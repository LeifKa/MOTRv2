# Fine-tuning MOTRv2's yolox_embed for D-FINE: Complete Guide

## ğŸ“‹ What You Have Now

I've created a complete fine-tuning system for you with:

### Documentation (3 files)
1. **FINE_TUNING_STEP_BY_STEP.md** - Detailed guide with explanations (READ THIS FIRST)
2. **QUICK_COMMANDS.md** - One-page cheat sheet with all commands
3. **README_FINETUNING.md** - This file (overview)

### Scripts (4 executable Python files)
1. **MOTRv2/finetune_for_dfine.py** - Main fine-tuning script
2. **MOTRv2/convert_to_gt.py** - Convert tracking results to ground truth
3. **merge_detections.py** - Merge multiple D-FINE detection files
4. **MOTRv2/visualize_tracking.py** - Create tracking visualization videos

### Configuration Files
1. **MOTRv2/configs/finetune_dfine.args** - Fine-tuning parameters

---

## ğŸ¯ Quick Start (30 Second Version)

You asked about two things:

### 1. Do I need D-FINE annotations?
**Answer:** You need TWO types of data:
- âœ… **D-FINE detections** (bounding boxes) - You generate these
- âœ… **Ground truth tracks** (person IDs across frames) - Use pseudo-labels from YOLOX+MOTRv2

### 2. Should I remove class filtering for training?
**Answer:** YES! For training data:
- Use `allowed_classes: [0]` (persons only, no ball)
- Use lower threshold `score_threshold: 0.3` (more detections)
- For inference/testing, keep higher threshold `0.7`

---

## ğŸš€ How to Proceed

### Path A: Just Want to Try It (Minimal Setup)

If you have just ONE training video:

```bash
# 1. Generate D-FINE training detections (10 min)
cd D-FINE
python tools/inference/torch_inf.py \
    -c configs/dfine/dfine_hgnetv2_l_coco.yml \
    -r dfine_l_obj365.pth \
    --input your_training_video.mp4 \
    --motrv2 \
    --sequence_name volleyball/train/game1
cp det_db_motrv2.json ../MOTRv2/det_db_train.json

# 2. Extract frames (5 min)
cd ../MOTRv2
mkdir -p data/Dataset/mot/volleyball/train/game1/img1
ffmpeg -i /path/to/your_training_video.mp4 \
    data/Dataset/mot/volleyball/train/game1/img1/%06d.jpg

# 3. Create pseudo ground truth with YOLOX (15 min)
python submit_dance.py \
    --resume motrv2_checkpoint.pth \
    --det_db det_db_yolox.json \
    --output_dir outputs/pseudo_gt
python convert_to_gt.py \
    --input outputs/pseudo_gt/game1.txt \
    --output data/Dataset/mot/volleyball/train/game1/gt/gt.txt

# 4. Create training list (1 min)
echo "volleyball/train/game1" > datasets/data_path/volleyball_train.txt

# 5. Fine-tune (1-2 hours)
python finetune_for_dfine.py @configs/finetune_dfine.args \
    --resume motrv2_checkpoint.pth \
    --det_db det_db_train.json \
    --epochs 2

# 6. Test on beach volleyball (10 min)
# ... (see QUICK_COMMANDS.md Step 6-9)
```

**Total time: ~2.5 hours**

### Path B: Comprehensive Setup (Multiple Videos)

If you have MULTIPLE training videos or want best results:

1. **Read:** [FINE_TUNING_STEP_BY_STEP.md](FINE_TUNING_STEP_BY_STEP.md) - Full guide
2. **Follow:** All 9 steps with multiple videos
3. **Result:** Better fine-tuned model

**Total time: ~4-5 hours**

---

## ğŸ“Š Understanding the Data Flow

```
Training Data Generation:
  Your Video â†’ D-FINE (threshold=0.3) â†’ Detections JSON
                                              â†“
  Your Video â†’ Extract Frames â†’ img1/*.jpg â†â”˜
                                              â†“
  Your Video â†’ YOLOX+MOTRv2 â†’ Pseudo GT â†’ gt/gt.txt

Training:
  Detections JSON + Frames + Ground Truth
                â†“
         Fine-tune yolox_embed (2 epochs)
                â†“
         checkpoint0001.pth

Testing:
  Beach Video â†’ D-FINE (threshold=0.7) â†’ Test Detections
                                              â†“
  Beach Video â†’ Extract Frames â†’ test/img1/*.jpg
                                              â†“
        Fine-tuned checkpoint + Test Detections
                                              â†“
                    Tracking Results â†’ Visualization
```

---

## ğŸ”§ Key Configuration Changes

### For Training Data (D-FINE)
```json
{
  "allowed_classes": [0],
  "score_threshold": 0.3
}
```
**Why:** More detections, only persons, better training signal

### For Testing Data (D-FINE)
```json
{
  "allowed_classes": [0],
  "score_threshold": 0.7
}
```
**Why:** Cleaner detections, better tracking performance

### For Fine-tuning (MOTRv2)
```bash
--lr 1e-5          # Very small learning rate
--epochs 2         # Short training
--embed_only True  # Only train yolox_embed
```
**Why:** Adapt embeddings without forgetting tracking skills

---

## ğŸ“ File Organization

After setup, your directory structure will look like:

```
BeachKI/
â”œâ”€â”€ D-FINE/
â”‚   â”œâ”€â”€ det_db_motrv2.json (generated)
â”‚   â”œâ”€â”€ motrv2_training_config.json (you create)
â”‚   â””â”€â”€ motrv2_test_config.json (you create)
â”‚
â”œâ”€â”€ MOTRv2/
â”‚   â”œâ”€â”€ inputs/                               â† NEW: Organized inputs
â”‚   â”‚   â”œâ”€â”€ detections/                       â† Detection JSON files
â”‚   â”‚   â”‚   â”œâ”€â”€ Beispielvideo_Beach_YOLOX.json
â”‚   â”‚   â”‚   â”œâ”€â”€ det_db_beach_volleyball.json
â”‚   â”‚   â”‚   â”œâ”€â”€ det_db_volleyball_train.json
â”‚   â”‚   â”‚   â””â”€â”€ det_db_volleyball_train_dfine.json
â”‚   â”‚   â””â”€â”€ videos/                           â† Source videos
â”‚   â”‚       â”œâ”€â”€ Beispielvideo_Beach_YOLOX.mp4
â”‚   â”‚       â””â”€â”€ Sequenz_Beach.mp4
â”‚   â”‚
â”‚   â”œâ”€â”€ weights/                              â† All model weights
â”‚   â”‚   â”œâ”€â”€ motrv2_dancetrack.pth
â”‚   â”‚   â””â”€â”€ r50_deformable_detr_plus_iterative_bbox_refinement-checkpoint.pth
â”‚   â”‚
â”‚   â”œâ”€â”€ data/Dataset/mot/
â”‚   â”‚   â”œâ”€â”€ det_db_volleyball_train_dfine.json  â† Copy of detection file (required here)
â”‚   â”‚   â””â”€â”€ volleyball/
â”‚   â”‚       â”œâ”€â”€ train/
â”‚   â”‚       â”‚   â””â”€â”€ game1/
â”‚   â”‚       â”‚       â”œâ”€â”€ img1/
â”‚   â”‚       â”‚       â”‚   â”œâ”€â”€ 000001.jpg  (6-digit format!)
â”‚   â”‚       â”‚       â”‚   â””â”€â”€ ...
â”‚   â”‚       â”‚       â””â”€â”€ gt/
â”‚   â”‚       â”‚           â””â”€â”€ gt.txt
â”‚   â”‚       â””â”€â”€ test/
â”‚   â”‚           â””â”€â”€ test1/
â”‚   â”‚               â”œâ”€â”€ img1/
â”‚   â”‚               â””â”€â”€ (no gt needed for testing)
â”‚   â”‚
â”‚   â”œâ”€â”€ datasets/data_path/
â”‚   â”‚   â””â”€â”€ volleyball_train.txt
â”‚   â”‚
â”‚   â”œâ”€â”€ outputs/
â”‚   â”‚   â”œâ”€â”€ finetune_dfine_embed/
â”‚   â”‚   â”‚   â””â”€â”€ checkpoint.pth â† FINE-TUNED MODEL
â”‚   â”‚   â”œâ”€â”€ inference_finetuned/
â”‚   â”‚   â”‚   â”œâ”€â”€ dfine_finetuned/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ game1.txt
â”‚   â”‚   â”‚   â””â”€â”€ tracking_visualization.mp4
â”‚   â”‚   â””â”€â”€ pseudo_labels/
â”‚   â”‚       â””â”€â”€ train_pseudo_gt/
â”‚   â”‚           â””â”€â”€ game1.txt
â”‚   â”‚
â”‚   â”œâ”€â”€ tools/
â”‚   â”‚   â”œâ”€â”€ fine_tuning/
â”‚   â”‚   â”‚   â””â”€â”€ finetune_for_dfine.py
â”‚   â”‚   â”œâ”€â”€ conversion/
â”‚   â”‚   â”‚   â””â”€â”€ convert_to_gt.py
â”‚   â”‚   â””â”€â”€ visualization/
â”‚   â”‚       â””â”€â”€ visualize_tracking.py
â”‚   â”‚
â”‚   â””â”€â”€ docs/
â”‚       â”œâ”€â”€ 00-OVERVIEW.md (this file)
â”‚       â”œâ”€â”€ 01-STEP_BY_STEP.md
â”‚       â”œâ”€â”€ 02-QUICK_COMMANDS.md
â”‚       â”œâ”€â”€ 03-ADVANCED.md
â”‚       â””â”€â”€ 04-THEORY.md
â”‚
â””â”€â”€ extract_frames.py
```

---

## âœ… Checklist: Before You Start

Make sure you have:

- [ ] D-FINE checkpoint (`dfine_l_obj365.pth`)
- [ ] MOTRv2 checkpoint (`motrv2_checkpoint.pth` or similar)
- [ ] At least ONE training video (volleyball footage)
- [ ] The beach volleyball test clip
- [ ] GPU with enough memory (8GB+ recommended)
- [ ] ~100GB free disk space (for frames)
- [ ] Python packages: torch, cv2, numpy

---

## ğŸ“ What Happens During Fine-tuning

```python
# Before fine-tuning:
yolox_embed.weight = [trained on YOLOX score distribution]
                           â†“
D-FINE score (0.85) â†’ pos2posemb() + yolox_embed
                           â†“
              Wrong embedding space
                           â†“
              Poor tracking results

# After fine-tuning:
yolox_embed.weight = [adapted to D-FINE score distribution]
                           â†“
D-FINE score (0.85) â†’ pos2posemb() + yolox_embed
                           â†“
              Correct embedding space
                           â†“
              Better tracking results
```

**Only 256 parameters train!** Everything else stays frozen.

---

## ğŸ“ˆ Expected Results

### Before Fine-tuning (Current)
- ID Switches: High
- Track Stability: Low
- Occlusion Handling: Poor

### After Fine-tuning (Expected)
- ID Switches: â†“ 30-40% reduction
- Track Stability: â†‘ Much more stable
- Occlusion Handling: â†‘ Improved

---

## ğŸ”§ Key Fixes Applied

During implementation, we encountered and fixed several issues:

### 1. Frame Numbering Format (datasets/dance.py:183, 206)
**Problem**: Code expected 8-digit format (`00000001.jpg`) but frames were 6-digit (`000001.jpg`)
**Fix**: Changed `f'{idx:08d}.jpg'` to `f'{idx:06d}.jpg'`

### 2. Detection Database Keys (submit_dance.py:50)
**Problem**: Code looked for keys with `.txt` extension but JSON had keys without extension
**Fix**: Changed `self.det_db[f_path[:-4] + '.txt']` to `self.det_db[f_path[:-4]]`

### 3. Dataset Loading (datasets/dance.py:68-88)
**Problem**: Hardcoded DanceTrack loading instead of reading from `data_txt_path`
**Fix**: Commented out DanceTrack loading, added code to load sequences from volleyball_train.txt

### 4. Class ID Differences (D-FINE config)
**Problem**: Objects365 uses class 1 for "person", COCO uses class 0
**Fix**: Removed class restrictions, kept only score threshold in motrv2_training_config.json

### 5. .DS_Store Files (macOS artifacts)
**Problem**: Training tried to process `.DS_Store` as a sequence directory
**Fix**: Removed with `find MOTRv2/data/Dataset/mot/DanceTrack -name ".DS_Store" -type f -delete`

### 6. Detection File Location
**Problem**: Training expects detection files in `data/Dataset/mot/` directory
**Fix**: Copied detection JSON to correct location

### 7. Hardcoded Sequence Path (submit_dance.py:200)
**Problem**: Script had hardcoded test path instead of train path
**Fix**: Changed `vids = ['volleyball/test/test1']` to `vids = ['volleyball/train/game1']`

---

## ğŸš¨ Common Issues & Solutions

| Issue | Solution |
|-------|----------|
| "No such file" errors | Check paths - use inputs/detections/ for JSON files |
| Frame format mismatch | Ensure frames are 6-digit: 000001.jpg not 00000001.jpg |
| Loss not decreasing | Try `--lr 5e-6` |
| Out of memory | Use `--batch_size 1 --sampler_lengths 3` |
| No improvement after training | Train for 3-4 epochs or use more training data |
| Bad tracking quality | Check detection quality with `--verify` flag |
| Class filter issues | Use score threshold only, remove class restrictions for Objects365 |
| .DS_Store errors | Remove with `find . -name ".DS_Store" -delete` |

---

## ğŸ“ Getting Help

1. **Start with:** [QUICK_COMMANDS.md](QUICK_COMMANDS.md) - Copy-paste commands
2. **Need details:** [FINE_TUNING_STEP_BY_STEP.md](FINE_TUNING_STEP_BY_STEP.md) - Full explanations
3. **Debug:** Check "Troubleshooting" sections in both docs

---

## ğŸ¯ Your Next Steps

**Right Now (5 minutes):**
1. Read [QUICK_COMMANDS.md](QUICK_COMMANDS.md)
2. Check if you have the prerequisites
3. Decide: Path A (quick) or Path B (comprehensive)

**Today (2-3 hours):**
1. Follow Path A to get first results
2. Generate training D-FINE detections
3. Create pseudo ground truth
4. Start fine-tuning

**This Week:**
1. Complete fine-tuning
2. Test on beach volleyball
3. Visualize and compare results
4. If needed, iterate with more data

---

## ğŸ’¡ Pro Tips

1. **Start small:** Use 1 training video first, add more if needed
2. **Monitor training:** Loss should decrease steadily
3. **Save checkpoints:** Keep both epoch 1 and 2, test both
4. **Visualize results:** Always compare with original model
5. **Document what works:** Take notes on what parameters work best

---

## ğŸ‰ Success Criteria

You'll know fine-tuning worked when:

- âœ… Training loss decreases from ~2.5 to ~1.5
- âœ… Fewer ID switches in test video
- âœ… More stable bounding boxes
- âœ… Better tracking through occlusions
- âœ… Consistent person IDs across frames

---

## Summary

**What you're doing:** Adapting MOTRv2's detection embedding to work with D-FINE instead of YOLOX

**How:** Fine-tuning just the `yolox_embed` layer (256 parameters)

**Data needed:**
- D-FINE detections (you generate)
- Pseudo ground truth (from YOLOX+MOTRv2)

**Time:** ~2-5 hours total

**Expected improvement:** 30-50% better tracking

**Next step:** Read [QUICK_COMMANDS.md](QUICK_COMMANDS.md) and start! ğŸš€

---

Good luck! Let me know if you hit any issues.
