# Fine-tuning MOTRv2's yolox_embed for D-FINE: Complete Guide

## ğŸ“‹ What You Have Now

I've created a complete fine-tuning system for you with:

### Documentation (3 files)
1. **FINE_TUNING_STEP_BY_STEP.md** - Detailed guide with explanations (READ THIS FIRST)
2. **QUICK_COMMANDS.md** - One-page cheat sheet with all commands
3. **README_FINETUNING.md** - This file (overview)

### Scripts (4 executable Python files)
1. **MOTRv2/finetune_for_dfine.py** - Main fine-tuning script
2. **MOTRv2/convert_to_gt.py** - Convert tracking results to ground truth
3. **merge_detections.py** - Merge multiple D-FINE detection files
4. **MOTRv2/visualize_tracking.py** - Create tracking visualization videos

### Configuration Files
1. **MOTRv2/configs/finetune_dfine.args** - Fine-tuning parameters

---

## ğŸ¯ Quick Start (30 Second Version)

You asked about two things:

### 1. Do I need D-FINE annotations?
**Answer:** You need TWO types of data:
- âœ… **D-FINE detections** (bounding boxes) - You generate these
- âœ… **Ground truth tracks** (person IDs across frames) - Use pseudo-labels from YOLOX+MOTRv2

### 2. Should I remove class filtering for training?
**Answer:** YES! For training data:
- Use `allowed_classes: [0]` (persons only, no ball)
- Use lower threshold `score_threshold: 0.3` (more detections)
- For inference/testing, keep higher threshold `0.7`

---

## ğŸš€ How to Proceed

### Path A: Just Want to Try It (Minimal Setup)

If you have just ONE training video:

```bash
# 1. Generate D-FINE training detections (10 min)
cd D-FINE
python tools/inference/torch_inf.py \
    -c configs/dfine/dfine_hgnetv2_l_coco.yml \
    -r dfine_l_obj365.pth \
    --input your_training_video.mp4 \
    --motrv2 \
    --sequence_name volleyball/train/game1
cp det_db_motrv2.json ../MOTRv2/det_db_train.json

# 2. Extract frames (5 min)
cd ../MOTRv2
mkdir -p data/Dataset/mot/volleyball/train/game1/img1
ffmpeg -i /path/to/your_training_video.mp4 \
    data/Dataset/mot/volleyball/train/game1/img1/%06d.jpg

# 3. Create pseudo ground truth with YOLOX (15 min)
python submit_dance.py \
    --resume motrv2_checkpoint.pth \
    --det_db det_db_yolox.json \
    --output_dir outputs/pseudo_gt
python convert_to_gt.py \
    --input outputs/pseudo_gt/game1.txt \
    --output data/Dataset/mot/volleyball/train/game1/gt/gt.txt

# 4. Create training list (1 min)
echo "volleyball/train/game1" > datasets/data_path/volleyball_train.txt

# 5. Fine-tune (1-2 hours)
python finetune_for_dfine.py @configs/finetune_dfine.args \
    --resume motrv2_checkpoint.pth \
    --det_db det_db_train.json \
    --epochs 2

# 6. Test on beach volleyball (10 min)
# ... (see QUICK_COMMANDS.md Step 6-9)
```

**Total time: ~2.5 hours**

### Path B: Comprehensive Setup (Multiple Videos)

If you have MULTIPLE training videos or want best results:

1. **Read:** [FINE_TUNING_STEP_BY_STEP.md](FINE_TUNING_STEP_BY_STEP.md) - Full guide
2. **Follow:** All 9 steps with multiple videos
3. **Result:** Better fine-tuned model

**Total time: ~4-5 hours**

---

## ğŸ“Š Understanding the Data Flow

```
Training Data Generation:
  Your Video â†’ D-FINE (threshold=0.3) â†’ Detections JSON
                                              â†“
  Your Video â†’ Extract Frames â†’ img1/*.jpg â†â”˜
                                              â†“
  Your Video â†’ YOLOX+MOTRv2 â†’ Pseudo GT â†’ gt/gt.txt

Training:
  Detections JSON + Frames + Ground Truth
                â†“
         Fine-tune yolox_embed (2 epochs)
                â†“
         checkpoint0001.pth

Testing:
  Beach Video â†’ D-FINE (threshold=0.7) â†’ Test Detections
                                              â†“
  Beach Video â†’ Extract Frames â†’ test/img1/*.jpg
                                              â†“
        Fine-tuned checkpoint + Test Detections
                                              â†“
                    Tracking Results â†’ Visualization
```

---

## ğŸ”§ Key Configuration Changes

### For Training Data (D-FINE)
```json
{
  "allowed_classes": [0],
  "score_threshold": 0.3
}
```
**Why:** More detections, only persons, better training signal

### For Testing Data (D-FINE)
```json
{
  "allowed_classes": [0],
  "score_threshold": 0.7
}
```
**Why:** Cleaner detections, better tracking performance

### For Fine-tuning (MOTRv2)
```bash
--lr 1e-5          # Very small learning rate
--epochs 2         # Short training
--embed_only True  # Only train yolox_embed
```
**Why:** Adapt embeddings without forgetting tracking skills

---

## ğŸ“ File Organization

After setup, your directory structure will look like:

```
BeachKI/
â”œâ”€â”€ D-FINE/
â”‚   â”œâ”€â”€ det_db_motrv2.json (generated)
â”‚   â”œâ”€â”€ motrv2_training_config.json (you create)
â”‚   â””â”€â”€ motrv2_test_config.json (you create)
â”‚
â”œâ”€â”€ MOTRv2/
â”‚   â”œâ”€â”€ data/Dataset/mot/volleyball/
â”‚   â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”‚   â””â”€â”€ game1/
â”‚   â”‚   â”‚       â”œâ”€â”€ img1/
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ 000001.jpg
â”‚   â”‚   â”‚       â”‚   â””â”€â”€ ...
â”‚   â”‚   â”‚       â””â”€â”€ gt/
â”‚   â”‚   â”‚           â””â”€â”€ gt.txt
â”‚   â”‚   â””â”€â”€ test/
â”‚   â”‚       â””â”€â”€ test1/
â”‚   â”‚           â”œâ”€â”€ img1/
â”‚   â”‚           â””â”€â”€ (no gt needed for testing)
â”‚   â”‚
â”‚   â”œâ”€â”€ datasets/data_path/
â”‚   â”‚   â””â”€â”€ volleyball_train.txt
â”‚   â”‚
â”‚   â”œâ”€â”€ outputs/
â”‚   â”‚   â”œâ”€â”€ finetune_dfine_embed/
â”‚   â”‚   â”‚   â”œâ”€â”€ checkpoint0001.pth â† FINE-TUNED MODEL
â”‚   â”‚   â”‚   â””â”€â”€ checkpoint0000.pth
â”‚   â”‚   â”œâ”€â”€ test_finetuned/
â”‚   â”‚   â”‚   â””â”€â”€ test1.txt
â”‚   â”‚   â””â”€â”€ test_original/
â”‚   â”‚       â””â”€â”€ test1.txt
â”‚   â”‚
â”‚   â”œâ”€â”€ det_db_volleyball_train.json
â”‚   â”œâ”€â”€ det_db_beach_test.json
â”‚   â”œâ”€â”€ finetune_for_dfine.py
â”‚   â”œâ”€â”€ convert_to_gt.py
â”‚   â””â”€â”€ visualize_tracking.py
â”‚
â”œâ”€â”€ merge_detections.py
â”œâ”€â”€ FINE_TUNING_STEP_BY_STEP.md â† READ THIS FIRST
â”œâ”€â”€ QUICK_COMMANDS.md
â””â”€â”€ README_FINETUNING.md (this file)
```

---

## âœ… Checklist: Before You Start

Make sure you have:

- [ ] D-FINE checkpoint (`dfine_l_obj365.pth`)
- [ ] MOTRv2 checkpoint (`motrv2_checkpoint.pth` or similar)
- [ ] At least ONE training video (volleyball footage)
- [ ] The beach volleyball test clip
- [ ] GPU with enough memory (8GB+ recommended)
- [ ] ~100GB free disk space (for frames)
- [ ] Python packages: torch, cv2, numpy

---

## ğŸ“ What Happens During Fine-tuning

```python
# Before fine-tuning:
yolox_embed.weight = [trained on YOLOX score distribution]
                           â†“
D-FINE score (0.85) â†’ pos2posemb() + yolox_embed
                           â†“
              Wrong embedding space
                           â†“
              Poor tracking results

# After fine-tuning:
yolox_embed.weight = [adapted to D-FINE score distribution]
                           â†“
D-FINE score (0.85) â†’ pos2posemb() + yolox_embed
                           â†“
              Correct embedding space
                           â†“
              Better tracking results
```

**Only 256 parameters train!** Everything else stays frozen.

---

## ğŸ“ˆ Expected Results

### Before Fine-tuning (Current)
- ID Switches: High
- Track Stability: Low
- Occlusion Handling: Poor

### After Fine-tuning (Expected)
- ID Switches: â†“ 30-40% reduction
- Track Stability: â†‘ Much more stable
- Occlusion Handling: â†‘ Improved

---

## ğŸš¨ Common Issues & Solutions

| Issue | Solution |
|-------|----------|
| "No such file" errors | Check paths in QUICK_COMMANDS.md |
| Loss not decreasing | Try `--lr 5e-6` |
| Out of memory | Use `--batch_size 1 --sampler_lengths 3` |
| No improvement after training | Train for 3-4 epochs or use more training data |
| Bad tracking quality | Check detection quality with `--verify` flag |

---

## ğŸ“ Getting Help

1. **Start with:** [QUICK_COMMANDS.md](QUICK_COMMANDS.md) - Copy-paste commands
2. **Need details:** [FINE_TUNING_STEP_BY_STEP.md](FINE_TUNING_STEP_BY_STEP.md) - Full explanations
3. **Debug:** Check "Troubleshooting" sections in both docs

---

## ğŸ¯ Your Next Steps

**Right Now (5 minutes):**
1. Read [QUICK_COMMANDS.md](QUICK_COMMANDS.md)
2. Check if you have the prerequisites
3. Decide: Path A (quick) or Path B (comprehensive)

**Today (2-3 hours):**
1. Follow Path A to get first results
2. Generate training D-FINE detections
3. Create pseudo ground truth
4. Start fine-tuning

**This Week:**
1. Complete fine-tuning
2. Test on beach volleyball
3. Visualize and compare results
4. If needed, iterate with more data

---

## ğŸ’¡ Pro Tips

1. **Start small:** Use 1 training video first, add more if needed
2. **Monitor training:** Loss should decrease steadily
3. **Save checkpoints:** Keep both epoch 1 and 2, test both
4. **Visualize results:** Always compare with original model
5. **Document what works:** Take notes on what parameters work best

---

## ğŸ‰ Success Criteria

You'll know fine-tuning worked when:

- âœ… Training loss decreases from ~2.5 to ~1.5
- âœ… Fewer ID switches in test video
- âœ… More stable bounding boxes
- âœ… Better tracking through occlusions
- âœ… Consistent person IDs across frames

---

## Summary

**What you're doing:** Adapting MOTRv2's detection embedding to work with D-FINE instead of YOLOX

**How:** Fine-tuning just the `yolox_embed` layer (256 parameters)

**Data needed:**
- D-FINE detections (you generate)
- Pseudo ground truth (from YOLOX+MOTRv2)

**Time:** ~2-5 hours total

**Expected improvement:** 30-50% better tracking

**Next step:** Read [QUICK_COMMANDS.md](QUICK_COMMANDS.md) and start! ğŸš€

---

Good luck! Let me know if you hit any issues.
